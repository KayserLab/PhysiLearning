# global configuration
global:
  transport_type: 'ipc://'
  transport_address: '/tmp/' # for raven use '/ptmp/saif/'
  evaluate_after: 0

# job configuration
job:
  nodes: 1
  ntasks: 1
  mem-per-task: 3000
  cpus-per-task: 1
  time: '15:00:00'
  agent_buffer: 1

# PhysiCell configuration
PhysiCell:
  cells: None

# Reinforcement learning configuration
learning:
  # Model options 
  model:
    name: 'PPO'
    n_envs: 1
    n_steps: 1000
    verbose: 1
    ent_coef: 0.01
    total_timesteps: 1.e+8
    save_freq: 1.e+7
    model_save_prefix: '070223_Jlikeparams_rewf=0_grf=1'
    load:
      enable_loading: 0
      external_file_loading: 0
      external_file_name: './data/LV_not_treat_pretrained'
# Environment configuration
env:
  # general env settings
  type: 'LV' #'PhysiCell' # 'LV'
  threshold_burden: 1000
  treatment_time_step: 60
  max_time: 120000
  reward_shaping: 0   # reward shaping flag for some predefined rewards

  # LV environment settings
  LV:
    initial_wt: 45
    initial_mut: 5
    carrying_capacity: 1500.0
    growth_rate_wt: 0.015 #0.0175
    growth_rate_mut: 0.01 #0.0175
    death_rate_wt: 0.001
    death_rate_mut: 0.001
    treat_death_rate_wt: 0.05 #0.015
    treat_death_rate_mut: 0.001 #0.0
    competition_wt: 3.0 #2400.0
    competition_mut: 1.0
    growth_function_flag: 1 # flag for growth function 0 - for delayed death, 1 - for immediate


  # note this is not yet functional
  PC:
    initial_wt: 45
    initial_mut: 5

      
